前提：
    1、当前的历史管理类中的处理，仅仅只能处理单个用户对上单个AI，缺乏高并发的异步处理。
    2、而且当前的视线，是硬读一个历史文件，每次加入新的历史记录，都需要凑头裁剪，而每次裁剪，都需要平凡的计算token，不论是时间和内存都被大量浪费了。
    3、当前的实现并不能持久化，记录数据，仅能记录少量的数据，一旦开始裁剪，一开始的问题，就找不到了，开始新的对话，当前的历史数据也会丢失。
解决：
    1、首先我想的是队列+字典+数据库，这个是整个数据结构的基调，或许后续会根据实际开发方便，性能优化，加入数据表、结构体、类什么的。
    2、数据库，顾名思义为了管理数据持久化，每次插入新的数据，就同步一份数据到数据库之中，而考虑到后续高并发的问题，并开发难度，选择MySQL。
    3、接着我们需要使用新的数据结构，核心思路是每次新的消息进入，先计算单个他的token，接着加到总token上，接着就看，他有没有超出上限，如果超出，先从数组的第零号位开始遍历，依次去见总token，逐渐减到总token，没有超过上限，接着我们看数据遍历到了哪一位，比如遍历到了第三位，那我们就删除下标0~2的数据，接着删除数组对应位置的历史消息。最后在字典和数组末尾插入新消息。
    4、关于多AI的兼容策略，我们首先想到的是

数据格式：    
    方案A：类 + 继承
        class SessionData:
            session_id: str
            token_counts: list[int]
            total_tokens: int
            def add_message(self, role, content): ...
            def to_request(self) -> dict: ...
        
        class OpenAISession(SessionData):
            messages: list[dict]  # [{role, content}, ...]
            model: str
            temperature: float
        class ClaudeSession(SessionData): ...
        class GeminiSession(SessionData): ...
    
    方案B：纯字典
        {
            "session_id": "xxx",
            "ai_type": "openai",
            "request_data": {
                "model": "gpt-4",
                "messages": [...],
                ...
            },
            "token_counts": [100, 50, 200],
            "total_tokens": 350
        }
    
    方案C：dataclass + 适配器
        @dataclass
        class Message:
            role: str
            content: str
        
        @dataclass
        class SessionData:
            session_id: str
            messages: list[Message]  # 统一格式，与AI无关
            token_counts: list[int]
            total_tokens: int
        
        class AIAdapter:
            def to_request(self, session: SessionData) -> dict: ...
            def from_response(self, response) -> Message: ...
        
        class OpenAIAdapter(AIAdapter): ...
        class ClaudeAdapter(AIAdapter): ...
    
    方案D：不可变数据结构
        @dataclass(frozen=True)
        class SessionData:
            session_id: str
            messages: tuple[Message, ...]
            token_counts: tuple[int, ...]
            total_tokens: int
            
            def add_message(self, msg, tokens) -> SessionData:
                return SessionData(
                    session_id=self.session_id,
                    messages=self.messages + (msg,),
                    token_counts=self.token_counts + (tokens,),
                    total_tokens=self.total_tokens + tokens
                )
                结果：已完成